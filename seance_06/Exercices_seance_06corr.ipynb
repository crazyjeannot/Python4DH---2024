{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1752f493-0963-47d8-b566-55da9b218705",
   "metadata": {},
   "source": [
    "# Exercices Seance 06\n",
    "\n",
    "## 1/ XML to CSV\n",
    "\n",
    "Écrire une fonction qui lit les 5 fichiers XML de Balzac, créé et sauvegarde un dataframe avec 8 colonnes : titre, auteur, gender, genre, canon, date_publication, date_naissance, date_mort\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3b95f6d-f05a-494c-a92b-f1cc72bebfc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from lxml import etree\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d914848c-ad21-436b-8516-65a2a92f71dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_folder_xml = \"/home/crazyjeannot/Documents/cours/2024/Python4DH/data/xml/*.xml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42f4ce8f-e504-4625-aa6a-16265adf49bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trouve_info(path_to_xml):\n",
    "    tree = etree.parse(path_to_xml)\n",
    "\n",
    "    titre = tree.find(\".//title\").text\n",
    "    auteur = tree.find(\".//author\").get('name')\n",
    "    gender = tree.find(\".//author\").get('sex')\n",
    "    date_naissance = tree.find(\".//author\").get('from')\n",
    "    date_mort = tree.find(\".//author\").get('to')\n",
    "    date_publication = tree.findall(\".//date\")[1].get('when')\n",
    "    canon = tree.find('.//profileDesc').get('tag')\n",
    "    genre = ' '.join([element.text for element in tree.findall('.//term')]) \n",
    "\n",
    "    return titre, auteur, gender, genre, canon, date_publication, date_naissance, date_mort\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c41bea57-6d2a-4ef7-a1cf-b06170eb6ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def moulinette(path_to_folder_xml):\n",
    "    df_corpus = pd.DataFrame([], columns=['titre', \"auteur\", \"gender\", \"genre\", \"canon\", \"date_publication\", \"date_naissance\", \"date_mort\"])\n",
    "    for doc in tqdm(glob(path_to_folder_xml)):\n",
    "        titre, auteur, gender, genre, canon, date_publication, date_naissance, date_mort = trouve_info(doc) \n",
    "    \n",
    "        df_roman = pd.DataFrame([(titre, auteur, gender, genre, canon, date_publication, date_naissance, date_mort)], columns=['titre', \"auteur\", \"gender\", \"genre\", \"canon\", \"date_publication\", \"date_naissance\", \"date_mort\"])\n",
    "        df_corpus = pd.concat([df_corpus, df_roman])\n",
    "    return df_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "573dc844-20ee-4da7-a940-c558147b8494",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cd75d3eaa854a8f9e2376c109a70adb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = moulinette(path_to_folder_xml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1de0c5b-50fe-411d-b8ee-c06d5118b161",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>titre</th>\n",
       "      <th>auteur</th>\n",
       "      <th>gender</th>\n",
       "      <th>genre</th>\n",
       "      <th>canon</th>\n",
       "      <th>date_publication</th>\n",
       "      <th>date_naissance</th>\n",
       "      <th>date_mort</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Le Chef-d'œuvre inconnu</td>\n",
       "      <td>Balzac, Honoré de</td>\n",
       "      <td>male</td>\n",
       "      <td>cycles et séries nouvelles</td>\n",
       "      <td>canon</td>\n",
       "      <td>1845</td>\n",
       "      <td>1799</td>\n",
       "      <td>1850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Eugénie Grandet</td>\n",
       "      <td>Balzac, Honoré de</td>\n",
       "      <td>male</td>\n",
       "      <td>cycles et séries</td>\n",
       "      <td>canon</td>\n",
       "      <td>1843</td>\n",
       "      <td>1799</td>\n",
       "      <td>1850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Le Père Goriot</td>\n",
       "      <td>Balzac, Honoré de</td>\n",
       "      <td>male</td>\n",
       "      <td>cycles et séries</td>\n",
       "      <td>canon</td>\n",
       "      <td>1843</td>\n",
       "      <td>1799</td>\n",
       "      <td>1850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sarrasine</td>\n",
       "      <td>Balzac, Honoré de</td>\n",
       "      <td>male</td>\n",
       "      <td>cycles et séries nouvelles</td>\n",
       "      <td>canon</td>\n",
       "      <td>1844</td>\n",
       "      <td>1799</td>\n",
       "      <td>1850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Illusions perdues</td>\n",
       "      <td>Balzac, Honoré de</td>\n",
       "      <td>male</td>\n",
       "      <td>cycles et séries</td>\n",
       "      <td>canon</td>\n",
       "      <td>1843</td>\n",
       "      <td>1799</td>\n",
       "      <td>1850</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     titre             auteur gender  \\\n",
       "0  Le Chef-d'œuvre inconnu  Balzac, Honoré de   male   \n",
       "0          Eugénie Grandet  Balzac, Honoré de   male   \n",
       "0           Le Père Goriot  Balzac, Honoré de   male   \n",
       "0                Sarrasine  Balzac, Honoré de   male   \n",
       "0        Illusions perdues  Balzac, Honoré de   male   \n",
       "\n",
       "                        genre  canon date_publication date_naissance date_mort  \n",
       "0  cycles et séries nouvelles  canon             1845           1799      1850  \n",
       "0            cycles et séries  canon             1843           1799      1850  \n",
       "0            cycles et séries  canon             1843           1799      1850  \n",
       "0  cycles et séries nouvelles  canon             1844           1799      1850  \n",
       "0            cycles et séries  canon             1843           1799      1850  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3692c346-a70b-4f09-a7ba-6a4e4712597b",
   "metadata": {},
   "source": [
    "## 2/ XML to txt \n",
    "\n",
    "Écrire une fonction qui convertie les 5 fichiers XML en fichiers txt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "418f8ce8-5706-4b79-815e-53f92d1bd6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_folder_txt = \"/home/crazyjeannot/Documents/cours/Python4DH/data/txt/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8ad943e8-173b-4088-9d55-6f4ec986b3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xml_to_txt(path_xml, path_name_res):\n",
    "    \n",
    "    chaine = \"\"\n",
    "    doc_name = os.path.splitext(os.path.basename(path_xml))[0]\n",
    "        \n",
    "    tree = etree.parse(path_xml)\n",
    "\n",
    "    if tree.findall(\".//p\"):\n",
    "        for line in tree.findall(\".//p\"):\n",
    "            if line.text:\n",
    "                chaine += line.text\n",
    "    else:\n",
    "        print(doc_name)\n",
    "                    \n",
    "    with open(path_name_res+doc_name+\".txt\", \"w\", encoding=\"utf8\") as file_out:\n",
    "        file_out.write(chaine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "be18903c-f313-4e21-adea-455155443970",
   "metadata": {},
   "outputs": [],
   "source": [
    "def moulinette_xmltotxt(path_name, path_name_res):\n",
    "    for doc in tqdm(glob(path_name)):\n",
    "        xml_to_txt(doc, path_name_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d95bfd1f-0f33-45a3-bbc1-4c5962cf055f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c6bbef2fe454a5596e9d59de65d95d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "moulinette_xmltotxt(path_to_folder_xml, path_to_folder_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6e4773-a1c2-4f9a-9a05-f947d8a8d31b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7cc56dcd-c0c3-4acc-8e34-51e0a79ad9f7",
   "metadata": {},
   "source": [
    "## 3/ Exploiter des JSON\n",
    "\n",
    "À partir des .book (json customisés) envoyés avec ce notebook, écrire une fonction qui ouvre les documents, une autre qui récupère la liste des verbes ('agent', 'patient') et des adjectifs ('mod') associés à ces personnages (les 10 premiers), une autre qui calcule leur fréquence d'apparition relative au nombre total de verbes / adjectifs et retourne le résultat sour la forme d'un dataframe (colonnes = mots, ligne = txt_j_personnage_i, valeurs = fréquence relative).\n",
    "\n",
    "Enfin définir une fonction main qui appelle ces différentes fonctions, fusionne les dataframes au fur et à mesure puis retourne le résultat sous la forme d'un dataframe (colonnes = mots, ligne = txt_j_personnage_i, valeurs = fréquence relative). \n",
    "\n",
    "Sauver ce dataframe final. Me l'envoyer avec votre notebook. \n",
    "\n",
    "Vous pouvez utiliser la fonction get_characterization vue dans le cours précédent.\n",
    "\n",
    "Vous pouvez également utiliser les fonctions déjà définies dans les différents exercices corrigés des semaines précédentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "60ea467d-9868-4409-88a3-15f36b4107c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "974cfe02-1eb0-44be-854c-b1bbfe84bd25",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_book = \"/home/crazyjeannot/Documents/cours/Python4DH/data/booknlp_output/booknlp_output_book/1830_Stendhal_Le-Rouge-et-le-noir.book\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0d1cf102-9ff8-4758-9067-938819578229",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_books = \"/home/crazyjeannot/Documents/cours/Python4DH/data/booknlp_output/booknlp_output_book/*.book\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "63dd9939-db2a-4bd9-88b2-f4433821f983",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_booknlp(path_book):\n",
    "    with open(path_book, \"r\") as booknlp_book:\n",
    "        book_data = json.load(booknlp_book)\n",
    "    return book_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4ef89483-6b38-45df-8f06-932a28efae26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_characterization(booknlp_data, N):\n",
    "    list_verb_suj, list_verb_obj, list_adj = [], [], []\n",
    "    for i in range(N):\n",
    "        list_verb_suj.append([item['w'] for item in booknlp_data[\"characters\"][i]['agent']])\n",
    "        list_verb_obj.append([item['w'] for item in booknlp_data[\"characters\"][i]['patient']])\n",
    "        list_adj.append([item['w'] for item in booknlp_data[\"characters\"][i]['mod']])\n",
    "    return list_verb_suj, list_verb_obj, list_adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3b5057c8-f488-464f-8a8d-83859d63ac19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frequence(list1, list2, list3):\n",
    "    list_dict_freq = []\n",
    "    for list_vsuj, list_vobj, list_adj in zip(list1, list2, list3):\n",
    "        conteur_mots_booknlp = dict(Counter(list_vsuj+list_vobj+list_adj))\n",
    "        dict_freq = {}\n",
    "        for key, value in conteur_mots_booknlp.items():\n",
    "            dict_freq[key] = conteur_mots_booknlp[key]/sum(conteur_mots_booknlp.values())\n",
    "        list_dict_freq.append(dict_freq) \n",
    "    return list_dict_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "49f6b51e-d18d-41a9-a640-3ae8b2bbe889",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(path_files, N=10):\n",
    "    df_main = pd.DataFrame()\n",
    "    index = []\n",
    "    i=1\n",
    "    for doc in tqdm(glob(path_files)):\n",
    "        data_booknlp = read_booknlp(doc)\n",
    "        list_verb_suj, list_verb_obj, list_adj = get_characterization(data_booknlp, N)\n",
    "        list_dict_freq = get_frequence(list_verb_suj, list_verb_obj, list_adj)\n",
    "        df_temp = pd.DataFrame(list_dict_freq)\n",
    "        df_main = pd.concat([df_main, df_temp])\n",
    "        index.extend([\"txt_\"+str(i)+\"_personnage_\"+str(j) for j in range(1, len(list_dict_freq)+1)])#txt_j_personnage_i\n",
    "        i+=1\n",
    "    df_main['index']=index\n",
    "    return df_main.set_index(\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9c7b2c45-ba67-4525-947a-dda6fc5b7955",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f6924aae0a14fed824c3ef0079f9eab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7547/1961434860.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_main['index']=index\n"
     ]
    }
   ],
   "source": [
    "df = main(path_books)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "44c259b8-72f4-428c-9427-409506bb1896",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>née</th>\n",
       "      <th>interrompait</th>\n",
       "      <th>parlait</th>\n",
       "      <th>plaisait</th>\n",
       "      <th>remplaçait</th>\n",
       "      <th>enfermait</th>\n",
       "      <th>atteignait</th>\n",
       "      <th>franchissait</th>\n",
       "      <th>avait</th>\n",
       "      <th>avançait</th>\n",
       "      <th>...</th>\n",
       "      <th>remua</th>\n",
       "      <th>rencontrèrent</th>\n",
       "      <th>cingla</th>\n",
       "      <th>posait</th>\n",
       "      <th>mettons</th>\n",
       "      <th>aperçois</th>\n",
       "      <th>souffleté</th>\n",
       "      <th>couchiez</th>\n",
       "      <th>Voyez</th>\n",
       "      <th>serrai</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>txt_1_personnage_1</th>\n",
       "      <td>0.006369</td>\n",
       "      <td>0.006369</td>\n",
       "      <td>0.012739</td>\n",
       "      <td>0.006369</td>\n",
       "      <td>0.006369</td>\n",
       "      <td>0.006369</td>\n",
       "      <td>0.006369</td>\n",
       "      <td>0.006369</td>\n",
       "      <td>0.006369</td>\n",
       "      <td>0.006369</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>txt_1_personnage_2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>txt_1_personnage_3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>txt_1_personnage_4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>txt_1_personnage_5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.012821</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>txt_7_personnage_6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>txt_7_personnage_7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>txt_7_personnage_8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.018182</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.018182</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>txt_7_personnage_9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.035088</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017544</td>\n",
       "      <td>0.017544</td>\n",
       "      <td>0.017544</td>\n",
       "      <td>0.017544</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>txt_7_personnage_10</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>0.020833</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70 rows × 4515 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          née  interrompait   parlait  plaisait  remplaçait  \\\n",
       "index                                                                         \n",
       "txt_1_personnage_1   0.006369      0.006369  0.012739  0.006369    0.006369   \n",
       "txt_1_personnage_2        NaN           NaN       NaN       NaN         NaN   \n",
       "txt_1_personnage_3        NaN           NaN       NaN       NaN         NaN   \n",
       "txt_1_personnage_4        NaN           NaN       NaN       NaN         NaN   \n",
       "txt_1_personnage_5        NaN           NaN       NaN       NaN         NaN   \n",
       "...                       ...           ...       ...       ...         ...   \n",
       "txt_7_personnage_6        NaN           NaN       NaN       NaN         NaN   \n",
       "txt_7_personnage_7        NaN           NaN       NaN       NaN         NaN   \n",
       "txt_7_personnage_8        NaN           NaN  0.018182       NaN         NaN   \n",
       "txt_7_personnage_9        NaN           NaN  0.035088       NaN         NaN   \n",
       "txt_7_personnage_10       NaN           NaN       NaN       NaN         NaN   \n",
       "\n",
       "                     enfermait  atteignait  franchissait     avait  avançait  \\\n",
       "index                                                                          \n",
       "txt_1_personnage_1    0.006369    0.006369      0.006369  0.006369  0.006369   \n",
       "txt_1_personnage_2         NaN         NaN           NaN       NaN       NaN   \n",
       "txt_1_personnage_3         NaN         NaN           NaN       NaN       NaN   \n",
       "txt_1_personnage_4         NaN         NaN           NaN       NaN       NaN   \n",
       "txt_1_personnage_5         NaN         NaN           NaN  0.012821       NaN   \n",
       "...                        ...         ...           ...       ...       ...   \n",
       "txt_7_personnage_6         NaN         NaN           NaN       NaN       NaN   \n",
       "txt_7_personnage_7         NaN         NaN           NaN       NaN       NaN   \n",
       "txt_7_personnage_8         NaN         NaN           NaN  0.018182       NaN   \n",
       "txt_7_personnage_9         NaN         NaN           NaN       NaN       NaN   \n",
       "txt_7_personnage_10        NaN         NaN           NaN  0.020833       NaN   \n",
       "\n",
       "                     ...     remua  rencontrèrent    cingla    posait  \\\n",
       "index                ...                                                \n",
       "txt_1_personnage_1   ...       NaN            NaN       NaN       NaN   \n",
       "txt_1_personnage_2   ...       NaN            NaN       NaN       NaN   \n",
       "txt_1_personnage_3   ...       NaN            NaN       NaN       NaN   \n",
       "txt_1_personnage_4   ...       NaN            NaN       NaN       NaN   \n",
       "txt_1_personnage_5   ...       NaN            NaN       NaN       NaN   \n",
       "...                  ...       ...            ...       ...       ...   \n",
       "txt_7_personnage_6   ...       NaN            NaN       NaN       NaN   \n",
       "txt_7_personnage_7   ...       NaN            NaN       NaN       NaN   \n",
       "txt_7_personnage_8   ...       NaN            NaN       NaN       NaN   \n",
       "txt_7_personnage_9   ...  0.017544       0.017544  0.017544  0.017544   \n",
       "txt_7_personnage_10  ...       NaN            NaN       NaN       NaN   \n",
       "\n",
       "                      mettons  aperçois  souffleté  couchiez     Voyez  \\\n",
       "index                                                                    \n",
       "txt_1_personnage_1        NaN       NaN        NaN       NaN       NaN   \n",
       "txt_1_personnage_2        NaN       NaN        NaN       NaN       NaN   \n",
       "txt_1_personnage_3        NaN       NaN        NaN       NaN       NaN   \n",
       "txt_1_personnage_4        NaN       NaN        NaN       NaN       NaN   \n",
       "txt_1_personnage_5        NaN       NaN        NaN       NaN       NaN   \n",
       "...                       ...       ...        ...       ...       ...   \n",
       "txt_7_personnage_6        NaN       NaN        NaN       NaN       NaN   \n",
       "txt_7_personnage_7        NaN       NaN        NaN       NaN       NaN   \n",
       "txt_7_personnage_8        NaN       NaN        NaN       NaN       NaN   \n",
       "txt_7_personnage_9        NaN       NaN        NaN       NaN       NaN   \n",
       "txt_7_personnage_10  0.020833  0.020833   0.020833  0.020833  0.020833   \n",
       "\n",
       "                       serrai  \n",
       "index                          \n",
       "txt_1_personnage_1        NaN  \n",
       "txt_1_personnage_2        NaN  \n",
       "txt_1_personnage_3        NaN  \n",
       "txt_1_personnage_4        NaN  \n",
       "txt_1_personnage_5        NaN  \n",
       "...                       ...  \n",
       "txt_7_personnage_6        NaN  \n",
       "txt_7_personnage_7        NaN  \n",
       "txt_7_personnage_8        NaN  \n",
       "txt_7_personnage_9        NaN  \n",
       "txt_7_personnage_10  0.020833  \n",
       "\n",
       "[70 rows x 4515 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "7c6b8032-c276-4ccb-b40a-02f476b8d577",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"resultat_ex_seance_06.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7450f0ba-6e29-475a-8327-69e639ffcf0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6876c88e-3600-4fb6-9094-d32d9ad8abad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plus simple: On prend la liste de verbes/adjectifs par roman et non par personnage ! bonus pour la suite, pas demandé dans l'exercice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a2938993-f4e6-4fe2-a163-c81a3e05af62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_booknlp(path_book):\n",
    "    with open(path_book, \"r\") as booknlp_book:\n",
    "        book_data = json.load(booknlp_book)\n",
    "    return book_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "99eb1966-9361-4b8a-99b0-9a75a2281b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_characterization(booknlp_data, N):\n",
    "    list_verb_suj, list_verb_obj, list_adj = [], [], []\n",
    "    for i in range(N):\n",
    "        list_verb_suj.extend([item['w'] for item in booknlp_data[\"characters\"][i]['agent']])\n",
    "        list_verb_obj.extend([item['w'] for item in booknlp_data[\"characters\"][i]['patient']])\n",
    "        list_adj.extend([item['w'] for item in booknlp_data[\"characters\"][i]['mod']])\n",
    "    return list_verb_suj, list_verb_obj, list_adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "50f6886b-6ef5-4994-ac12-11830714257b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frequence(list1, list2, list3, M):\n",
    "    conteur_mots_booknlp = dict(Counter(list1+list2+list3).most_common(M))\n",
    "    dict_freq = {}\n",
    "    for key, value in conteur_mots_booknlp.items():\n",
    "        dict_freq[key] = conteur_mots_booknlp[key]/sum(conteur_mots_booknlp.values())\n",
    "    return dict_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1ecc6035-6644-43e8-9ad6-ae783eadb9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(path_files, N=10, M=5000):\n",
    "    df_main = pd.DataFrame()\n",
    "    index = []\n",
    "    i=1\n",
    "    for doc in tqdm(glob(path_files)):\n",
    "        doc_name = os.path.splitext(os.path.basename(doc))[0]\n",
    "\n",
    "        data_booknlp = read_booknlp(doc)\n",
    "        list_verb_suj, list_verb_obj, list_adj = get_characterization(data_booknlp, N)\n",
    "        dict_freq = get_frequence(list_verb_suj, list_verb_obj, list_adj, M)\n",
    "        df_temp = pd.DataFrame.from_dict(dict_freq, orient='index')\n",
    "        df_main = pd.concat([df_main, df_temp.T])\n",
    "        index.append(doc_name)\n",
    "        i+=1\n",
    "    df_main['index']=index\n",
    "    return df_main.set_index(\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a1866424-5f2c-4535-a093-b0383bb7923e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fc90f822ebc4ce7be3f80722f9d4ce8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7547/2440555551.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_main['index']=index\n"
     ]
    }
   ],
   "source": [
    "df = main(path_books, N=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "aecafdcb-e92d-45e6-8bca-1a70fa8858a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>disait</th>\n",
       "      <th>sais</th>\n",
       "      <th>dit</th>\n",
       "      <th>ai</th>\n",
       "      <th>vois</th>\n",
       "      <th>avait</th>\n",
       "      <th>connu</th>\n",
       "      <th>vue</th>\n",
       "      <th>crois</th>\n",
       "      <th>vu</th>\n",
       "      <th>...</th>\n",
       "      <th>serrai</th>\n",
       "      <th>gros</th>\n",
       "      <th>pacifique</th>\n",
       "      <th>bienveillant</th>\n",
       "      <th>magnanime</th>\n",
       "      <th>prisonnier</th>\n",
       "      <th>face</th>\n",
       "      <th>grossier</th>\n",
       "      <th>Monsieur</th>\n",
       "      <th>patron</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1930_Colette_Sido</th>\n",
       "      <td>0.018895</td>\n",
       "      <td>0.015988</td>\n",
       "      <td>0.014535</td>\n",
       "      <td>0.011628</td>\n",
       "      <td>0.010174</td>\n",
       "      <td>0.008721</td>\n",
       "      <td>0.008721</td>\n",
       "      <td>0.008721</td>\n",
       "      <td>0.008721</td>\n",
       "      <td>0.008721</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1907_Leblanc-Maurice_Arsene-Lupin-gentleman-cambrioleur</th>\n",
       "      <td>0.001227</td>\n",
       "      <td>0.003067</td>\n",
       "      <td>0.018405</td>\n",
       "      <td>0.009202</td>\n",
       "      <td>0.003067</td>\n",
       "      <td>0.009202</td>\n",
       "      <td>0.003681</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002454</td>\n",
       "      <td>0.009202</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1841_Sand-George_Un-hiver-a-Majorque</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.010076</td>\n",
       "      <td>0.012594</td>\n",
       "      <td>0.007557</td>\n",
       "      <td>0.005038</td>\n",
       "      <td>0.002519</td>\n",
       "      <td>0.002519</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.012594</td>\n",
       "      <td>0.010076</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1892_Verne-Jules_Le-Chateau-des-Carpathes</th>\n",
       "      <td>0.001967</td>\n",
       "      <td>0.003934</td>\n",
       "      <td>0.012459</td>\n",
       "      <td>0.001311</td>\n",
       "      <td>0.000656</td>\n",
       "      <td>0.013770</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.003279</td>\n",
       "      <td>0.001311</td>\n",
       "      <td>0.004590</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1830_Stendhal_Le-Rouge-et-le-noir</th>\n",
       "      <td>0.008912</td>\n",
       "      <td>0.003055</td>\n",
       "      <td>0.022406</td>\n",
       "      <td>0.009930</td>\n",
       "      <td>0.003692</td>\n",
       "      <td>0.021388</td>\n",
       "      <td>0.001400</td>\n",
       "      <td>0.000382</td>\n",
       "      <td>0.002164</td>\n",
       "      <td>0.003947</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1909_Zevaco-Michel_Nostradamus</th>\n",
       "      <td>0.004381</td>\n",
       "      <td>0.005958</td>\n",
       "      <td>0.035921</td>\n",
       "      <td>0.006483</td>\n",
       "      <td>0.002979</td>\n",
       "      <td>0.004381</td>\n",
       "      <td>0.001227</td>\n",
       "      <td>0.001227</td>\n",
       "      <td>0.002453</td>\n",
       "      <td>0.007885</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1883_Guy-de-Maupassant_Contes-de-la-Becasse</th>\n",
       "      <td>0.007692</td>\n",
       "      <td>0.003846</td>\n",
       "      <td>0.007692</td>\n",
       "      <td>0.006410</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.006410</td>\n",
       "      <td>0.001282</td>\n",
       "      <td>0.002564</td>\n",
       "      <td>0.003846</td>\n",
       "      <td>0.002564</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001282</td>\n",
       "      <td>0.001282</td>\n",
       "      <td>0.001282</td>\n",
       "      <td>0.001282</td>\n",
       "      <td>0.001282</td>\n",
       "      <td>0.001282</td>\n",
       "      <td>0.001282</td>\n",
       "      <td>0.001282</td>\n",
       "      <td>0.001282</td>\n",
       "      <td>0.001282</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7 rows × 4515 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      disait      sais  \\\n",
       "index                                                                    \n",
       "1930_Colette_Sido                                   0.018895  0.015988   \n",
       "1907_Leblanc-Maurice_Arsene-Lupin-gentleman-cam...  0.001227  0.003067   \n",
       "1841_Sand-George_Un-hiver-a-Majorque                     NaN  0.010076   \n",
       "1892_Verne-Jules_Le-Chateau-des-Carpathes           0.001967  0.003934   \n",
       "1830_Stendhal_Le-Rouge-et-le-noir                   0.008912  0.003055   \n",
       "1909_Zevaco-Michel_Nostradamus                      0.004381  0.005958   \n",
       "1883_Guy-de-Maupassant_Contes-de-la-Becasse         0.007692  0.003846   \n",
       "\n",
       "                                                         dit        ai  \\\n",
       "index                                                                    \n",
       "1930_Colette_Sido                                   0.014535  0.011628   \n",
       "1907_Leblanc-Maurice_Arsene-Lupin-gentleman-cam...  0.018405  0.009202   \n",
       "1841_Sand-George_Un-hiver-a-Majorque                0.012594  0.007557   \n",
       "1892_Verne-Jules_Le-Chateau-des-Carpathes           0.012459  0.001311   \n",
       "1830_Stendhal_Le-Rouge-et-le-noir                   0.022406  0.009930   \n",
       "1909_Zevaco-Michel_Nostradamus                      0.035921  0.006483   \n",
       "1883_Guy-de-Maupassant_Contes-de-la-Becasse         0.007692  0.006410   \n",
       "\n",
       "                                                        vois     avait  \\\n",
       "index                                                                    \n",
       "1930_Colette_Sido                                   0.010174  0.008721   \n",
       "1907_Leblanc-Maurice_Arsene-Lupin-gentleman-cam...  0.003067  0.009202   \n",
       "1841_Sand-George_Un-hiver-a-Majorque                0.005038  0.002519   \n",
       "1892_Verne-Jules_Le-Chateau-des-Carpathes           0.000656  0.013770   \n",
       "1830_Stendhal_Le-Rouge-et-le-noir                   0.003692  0.021388   \n",
       "1909_Zevaco-Michel_Nostradamus                      0.002979  0.004381   \n",
       "1883_Guy-de-Maupassant_Contes-de-la-Becasse              NaN  0.006410   \n",
       "\n",
       "                                                       connu       vue  \\\n",
       "index                                                                    \n",
       "1930_Colette_Sido                                   0.008721  0.008721   \n",
       "1907_Leblanc-Maurice_Arsene-Lupin-gentleman-cam...  0.003681       NaN   \n",
       "1841_Sand-George_Un-hiver-a-Majorque                0.002519       NaN   \n",
       "1892_Verne-Jules_Le-Chateau-des-Carpathes                NaN  0.003279   \n",
       "1830_Stendhal_Le-Rouge-et-le-noir                   0.001400  0.000382   \n",
       "1909_Zevaco-Michel_Nostradamus                      0.001227  0.001227   \n",
       "1883_Guy-de-Maupassant_Contes-de-la-Becasse         0.001282  0.002564   \n",
       "\n",
       "                                                       crois        vu  ...  \\\n",
       "index                                                                   ...   \n",
       "1930_Colette_Sido                                   0.008721  0.008721  ...   \n",
       "1907_Leblanc-Maurice_Arsene-Lupin-gentleman-cam...  0.002454  0.009202  ...   \n",
       "1841_Sand-George_Un-hiver-a-Majorque                0.012594  0.010076  ...   \n",
       "1892_Verne-Jules_Le-Chateau-des-Carpathes           0.001311  0.004590  ...   \n",
       "1830_Stendhal_Le-Rouge-et-le-noir                   0.002164  0.003947  ...   \n",
       "1909_Zevaco-Michel_Nostradamus                      0.002453  0.007885  ...   \n",
       "1883_Guy-de-Maupassant_Contes-de-la-Becasse         0.003846  0.002564  ...   \n",
       "\n",
       "                                                      serrai      gros  \\\n",
       "index                                                                    \n",
       "1930_Colette_Sido                                        NaN       NaN   \n",
       "1907_Leblanc-Maurice_Arsene-Lupin-gentleman-cam...       NaN       NaN   \n",
       "1841_Sand-George_Un-hiver-a-Majorque                     NaN       NaN   \n",
       "1892_Verne-Jules_Le-Chateau-des-Carpathes                NaN       NaN   \n",
       "1830_Stendhal_Le-Rouge-et-le-noir                        NaN       NaN   \n",
       "1909_Zevaco-Michel_Nostradamus                           NaN       NaN   \n",
       "1883_Guy-de-Maupassant_Contes-de-la-Becasse         0.001282  0.001282   \n",
       "\n",
       "                                                    pacifique  bienveillant  \\\n",
       "index                                                                         \n",
       "1930_Colette_Sido                                         NaN           NaN   \n",
       "1907_Leblanc-Maurice_Arsene-Lupin-gentleman-cam...        NaN           NaN   \n",
       "1841_Sand-George_Un-hiver-a-Majorque                      NaN           NaN   \n",
       "1892_Verne-Jules_Le-Chateau-des-Carpathes                 NaN           NaN   \n",
       "1830_Stendhal_Le-Rouge-et-le-noir                         NaN           NaN   \n",
       "1909_Zevaco-Michel_Nostradamus                            NaN           NaN   \n",
       "1883_Guy-de-Maupassant_Contes-de-la-Becasse          0.001282      0.001282   \n",
       "\n",
       "                                                    magnanime  prisonnier  \\\n",
       "index                                                                       \n",
       "1930_Colette_Sido                                         NaN         NaN   \n",
       "1907_Leblanc-Maurice_Arsene-Lupin-gentleman-cam...        NaN         NaN   \n",
       "1841_Sand-George_Un-hiver-a-Majorque                      NaN         NaN   \n",
       "1892_Verne-Jules_Le-Chateau-des-Carpathes                 NaN         NaN   \n",
       "1830_Stendhal_Le-Rouge-et-le-noir                         NaN         NaN   \n",
       "1909_Zevaco-Michel_Nostradamus                            NaN         NaN   \n",
       "1883_Guy-de-Maupassant_Contes-de-la-Becasse          0.001282    0.001282   \n",
       "\n",
       "                                                        face  grossier  \\\n",
       "index                                                                    \n",
       "1930_Colette_Sido                                        NaN       NaN   \n",
       "1907_Leblanc-Maurice_Arsene-Lupin-gentleman-cam...       NaN       NaN   \n",
       "1841_Sand-George_Un-hiver-a-Majorque                     NaN       NaN   \n",
       "1892_Verne-Jules_Le-Chateau-des-Carpathes                NaN       NaN   \n",
       "1830_Stendhal_Le-Rouge-et-le-noir                        NaN       NaN   \n",
       "1909_Zevaco-Michel_Nostradamus                           NaN       NaN   \n",
       "1883_Guy-de-Maupassant_Contes-de-la-Becasse         0.001282  0.001282   \n",
       "\n",
       "                                                    Monsieur    patron  \n",
       "index                                                                   \n",
       "1930_Colette_Sido                                        NaN       NaN  \n",
       "1907_Leblanc-Maurice_Arsene-Lupin-gentleman-cam...       NaN       NaN  \n",
       "1841_Sand-George_Un-hiver-a-Majorque                     NaN       NaN  \n",
       "1892_Verne-Jules_Le-Chateau-des-Carpathes                NaN       NaN  \n",
       "1830_Stendhal_Le-Rouge-et-le-noir                        NaN       NaN  \n",
       "1909_Zevaco-Michel_Nostradamus                           NaN       NaN  \n",
       "1883_Guy-de-Maupassant_Contes-de-la-Becasse         0.001282  0.001282  \n",
       "\n",
       "[7 rows x 4515 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "dc0b9754-548d-4043-b108-49f497825daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('resultat_roman_ex_seance_06.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b8f0d303-e99e-4908-8921-df2b8ec6442e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['embrassais', 'violenter', 'pressant', 'posait', 'Voyez', 'serrai',\n",
       "       'gros', 'pacifique', 'bienveillant', 'magnanime', 'prisonnier', 'face',\n",
       "       'grossier', 'Monsieur', 'patron'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns[4500:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00daef27-7788-4028-8133-615983ddfbed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
